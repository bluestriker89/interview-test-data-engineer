# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in the kedro docs under `Accessing data`
# You can access the kedro docs by running `kedro docs`

#
# An example data set definition can look as follows:
#
#cars.csv:
#  type: CSVLocalDataSet # https://kedro.readthedocs.io/en/latest/kedro.io.CSVLocalDataSet.html
#  filepath: data/01_raw/company/cars.csv
#  load_args: # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
#    sep: ','
#    skiprows: 0
#    # skipfooter: 1
#    # engine: python  # Some of the features including skipfooter is only available in python engine
#    engine: c  # This is a faster option
#    na_values: ['#NA', 'NA']
#  save_args: # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html
#    index: False
#    date_format: '%Y-%m-%d %H:%M'
#    decimal: '.'
#
#cars.csv.s3:
#  type: CSVS3DataSet # https://kedro.readthedocs.io/en/latest/kedro.io.CSVS3DataSet.html
#  filepath: data/02_intermediate/company/cars.csv
#  bucket_name: my_bucket
#  credentials: dev_s3
#  load_args: # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
#    sep: ','
#    skiprows: 5
#    skipfooter: 1
#    na_values: ['#NA', 'NA']
#    index: False
#  save_args: # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html
#    index: False
#    date_format: '%Y-%m-%d %H:%M'
#    decimal: '.'
#
#cars.hdf:
#  type: HDFLocalDataSet  # https://kedro.readthedocs.io/en/latest/kedro.io.HDFLocalDataSet.html
#  filepath: data/02_intermediate/cars.hdf
#  key: name
#  load_args:  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_hdf.html
#    columns: ['engine', 'name']
#  save_args:  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html
#    mode: 'w'  # Overwrite even when the file already exists
#    # mode: 'a'  # Appends or creates a file
#    # mode: '+r'  # Appends an existing file
#    dropna: True
#
#cars.hdf.s3:
#  type: HDFS3DataSet  # https://kedro.readthedocs.io/en/latest/kedro.io.HDFS3DataSet.html
#  filepath: data/02_intermediate/cars.hdf
#  bucket_name: my_bucket
#  key: hdf_key
#  credentials: dev_s3
#  load_args:
#  save_args:
#
#cars.parquet:
#  type: ParquetLocalDataSet  # https://kedro.readthedocs.io/en/latest/kedro.io.ParquetLocalDataSet.html
#  filepath: data/02_intermediate/cars.parquet
#  load_args:
#    columns: ['name', 'gear','disp', 'wt']
#  save_args:
#     compression: 'GZIP'
#
#cars.sql:
#  type: SQLTableDataSet  # https://kedro.readthedocs.io/en/latest/kedro.io.SQLTableDataSet.html
#  credentials: dev_postgres
#  table_name: cars
#  load_args:  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html
#    index_col: ['name']
#    columns: ['name', 'gear']
#  save_args:  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html
#    if_exists: 'replace'
#    # if_exists: 'fail'
#    # if_exists: 'append'
#
#cars.sql.query:
#  type: SQLQueryDataSet  # https://kedro.readthedocs.io/en/latest/kedro.io.SQLQueryDataSet.html
#  credentials: dev_postgres
#  sql: 'select * from cars where gear=4'
#  load_args:  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html
#    index_col: ['name']
#
#car_model.pkl:
#  type: PickleLocalDataSet
#  filepath: data/06_models/car_model.pkl
#  backend: pickle
#
## Templating and reuse
#
#_csv: &csv
#  type: kedro.contrib.io.pyspark.spark_data_set.SparkDataSet
#  file_format: 'csv'
#  load_args:
#    header: True
#    inferSchema: False
#
#raw_banana_trials:
#  <<: *csv
#  filepath: "s3a://supermarket/01_raw/Banana/trials.csv"



# This is a data set used by the example pipeline provided with the projected
# template. Please feel free to remove it once you remove the example pipeline.
example_iris_data:
  type: CSVLocalDataSet
  filepath: data/01_raw/iris.csv

raw_customer:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/customer.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_lineitem:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/lineitem.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_nation:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/nation.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_orders:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/orders.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_part:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/part.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_partsupp:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/partsupp.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_region:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/region.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

raw_supplier:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/01_raw/supplier.tbl
  file_format: csv
  load_args:
    header: False
    inferSchema: True
    sep: '|'

prim_customer:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_customer
  save_args:
    mode: Overwrite

prim_lineitem:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_lineitem
  save_args:
    mode: Overwrite

prim_nation:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_nation
  save_args:
    mode: Overwrite

prim_orders:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_orders
  save_args:
    mode: Overwrite

prim_part:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_part
  save_args:
    mode: Overwrite

prim_partsupp:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_partsupp
  save_args:
    mode: Overwrite

prim_region:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_region
  save_args:
    mode: Overwrite

prim_supplier:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/03_primary/prim_supplier
  save_args:
    mode: Overwrite

customer_dimension:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/04_features/customer_dimension
  save_args:
    mode: Overwrite

part_dimension:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/04_features/part_dimension
  save_args:
    mode: Overwrite

supplier_dimension:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/04_features/supplier_dimension
  save_args:
    mode: Overwrite

order_fact:
  type: kedro.contrib.io.pyspark.SparkDataSet
  filepath: data/04_features/order_fact
  save_args:
    mode: Overwrite