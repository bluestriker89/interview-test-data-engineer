{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 20:23:09,393 - root - INFO - ** Kedro project prospa\n",
      "2019-06-29 20:23:09,396 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/logging.yml\n",
      "2019-06-29 20:23:09,401 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/catalog.yml\n",
      "2019-06-29 20:23:09,404 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/credentials.yml\n",
      "2019-06-29 20:23:09,406 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/parameters.yml\n",
      "2019-06-29 20:23:09,410 - root - INFO - Defined global variables proj_dir, proj_name, conf and io\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 20:23:09,426 - kedro.io.data_catalog - INFO - Loading data from `customer_dimension` (SparkDataSet)...\n",
      "2019-06-29 20:23:14,613 - kedro.io.data_catalog - INFO - Loading data from `part_dimension` (SparkDataSet)...\n",
      "2019-06-29 20:23:14,791 - kedro.io.data_catalog - INFO - Loading data from `supplier_dimension` (SparkDataSet)...\n",
      "2019-06-29 20:23:14,965 - kedro.io.data_catalog - INFO - Loading data from `order_fact` (SparkDataSet)...\n"
     ]
    }
   ],
   "source": [
    "customer_dimension = io.load(\"customer_dimension\")\n",
    "part_dimension = io.load(\"part_dimension\")\n",
    "supplier_dimension = io.load(\"supplier_dimension\")\n",
    "order_fact = io.load(\"order_fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dimension.registerTempTable(\"customer_dimension\")\n",
    "part_dimension.registerTempTable(\"part_dimension\")\n",
    "supplier_dimension.registerTempTable(\"supplier_dimension\")\n",
    "order_fact.registerTempTable(\"order_fact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the top 5 nations in terms of revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------+\n",
      "|Supplier_Country_Name|Supplier_Country_Revenue|\n",
      "+---------------------+------------------------+\n",
      "|        UNITED STATES|    1.7302219152000004E8|\n",
      "|                CHINA|    1.5443322854000002E8|\n",
      "|           MOZAMBIQUE|    1.4746607397999978E8|\n",
      "|              VIETNAM|    1.2989473344999981E8|\n",
      "|                EGYPT|    1.2832393222000003E8|\n",
      "+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT SD.Supplier_Country_Name\\\n",
    "                    ,SUM(OR.Order_Line_Revenue) AS Supplier_Country_Revenue\\\n",
    "                FROM order_fact OR \\\n",
    "          INNER JOIN supplier_dimension SD\\\n",
    "                  ON OR.Order_Supplier_Key=SD.Supplier_Key\\\n",
    "            GROUP BY SD.Supplier_Country_Name\\\n",
    "            ORDER BY Supplier_Country_Revenue DESC\").limit(5)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the top 5 nations, what is the most common shipping mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"Top_5_Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|Order_Ship_Mode|Shipping_Count|\n",
      "+---------------+--------------+\n",
      "|            FOB|           911|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ship=spark.sql(\"SELECT OR.Order_Ship_Mode\\\n",
    "                    ,COUNT(DISTINCT OR.Order_Customer_Key) AS Shipping_Count \\\n",
    "                FROM order_fact OR \\\n",
    "          INNER JOIN supplier_dimension SD\\\n",
    "                  ON OR.Order_Supplier_Key=SD.Supplier_Key\\\n",
    "               WHERE SD.Supplier_Country_Name IN (SELECT Supplier_Country_Name FROM Top_5_Nations) \\\n",
    "            GROUP BY OR.Order_Ship_Mode\\\n",
    "            ORDER BY Shipping_Count DESC\").limit(1)\n",
    "df_ship.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the top selling months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|Year_Month|     Monthly_Revenue|\n",
      "+----------+--------------------+\n",
      "|    199310|       3.117616533E7|\n",
      "|    199312|3.1122497909999996E7|\n",
      "|    199201|3.0878726890000023E7|\n",
      "|    199608|3.0497227109999996E7|\n",
      "|    199512| 3.043916234000001E7|\n",
      "|    199401| 3.032269908999999E7|\n",
      "|    199309|3.0234220019999996E7|\n",
      "|    199405|3.0015042540000007E7|\n",
      "|    199409|2.9820136109999992E7|\n",
      "|    199203|2.9758230360000014E7|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sell=spark.sql(\"SELECT YEAR(Order_Date)*100 + MONTH(Order_Date) AS Year_Month\\\n",
    "                         ,SUM(Order_Line_Revenue) AS Monthly_Revenue\\\n",
    "                     FROM order_fact\\\n",
    "                 GROUP BY Year_Month\\\n",
    "                 ORDER BY Monthly_Revenue DESC\")\n",
    "df_sell.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who are the top customer in terms of revenue and/or quantity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     Customer_Name| Customer_Revenue|\n",
      "+------------------+-----------------+\n",
      "|Customer#000001489|        5457263.4|\n",
      "|Customer#000000214|        4742494.2|\n",
      "|Customer#000000073|       4714752.19|\n",
      "|Customer#000001396|4678182.200000001|\n",
      "|Customer#000001246|       4676314.75|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CD.Customer_Name\\\n",
    "                 ,SUM(OR.Order_Line_Revenue) AS Customer_Revenue\\\n",
    "             FROM order_fact OR \\\n",
    "       INNER JOIN customer_dimension CD\\\n",
    "               ON OR.Order_Customer_Key=CD.Customer_Key\\\n",
    "         GROUP BY CD.Customer_Name\\\n",
    "         ORDER BY Customer_Revenue DESC\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     Customer_Name|Customer_Quantity|\n",
      "+------------------+-----------------+\n",
      "|Customer#000001489|             3868|\n",
      "|Customer#000001396|             3408|\n",
      "|Customer#000000073|             3384|\n",
      "|Customer#000000214|             3369|\n",
      "|Customer#000000898|             3309|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CD.Customer_Name\\\n",
    "                 ,SUM(OR.Order_Line_Quantity) AS Customer_Quantity\\\n",
    "             FROM order_fact OR \\\n",
    "       INNER JOIN customer_dimension CD\\\n",
    "               ON OR.Order_Customer_Key=CD.Customer_Key\\\n",
    "         GROUP BY CD.Customer_Name\\\n",
    "         ORDER BY Customer_Quantity DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the sales revenue of on current period against previous period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revn=spark.sql(\"SELECT YEAR(Order_Date)*100 + MONTH(Order_Date) AS Year_Month\\\n",
    "                         ,SUM(Order_Line_Revenue) AS Monthly_Revenue\\\n",
    "                     FROM order_fact\\\n",
    "                 GROUP BY Year_Month\")\n",
    "df_revn.registerTempTable(\"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "|Year_Month|     Monthly_Revenue|Last_12_Monthly_Revenue|Difference_Between_Previous_Year_Monthly_Revenue|\n",
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "|    199201|3.0878726890000023E7|                   null|                                            null|\n",
      "|    199202|2.5019705100000005E7|                   null|                                            null|\n",
      "|    199203|2.9758230360000014E7|                   null|                                            null|\n",
      "|    199204|       2.805256204E7|                   null|                                            null|\n",
      "|    199205|        2.78214501E7|                   null|                                            null|\n",
      "|    199206|2.5229275750000007E7|                   null|                                            null|\n",
      "|    199207|2.6655226179999992E7|                   null|                                            null|\n",
      "|    199208|2.9252365159999996E7|                   null|                                            null|\n",
      "|    199209|2.7764384579999983E7|                   null|                                            null|\n",
      "|    199210|2.6952884110000007E7|                   null|                                            null|\n",
      "|    199211|2.2511156680000007E7|                   null|                                            null|\n",
      "|    199212|2.4845838199999984E7|                   null|                                            null|\n",
      "|    199301|         2.6129413E7|   3.0878726890000023E7|                              -4749313.890000023|\n",
      "|    199302|2.6187775310000002E7|   2.5019705100000005E7|                              1168070.2099999972|\n",
      "|    199303|2.4816713409999993E7|   2.9758230360000014E7|                              -4941516.950000022|\n",
      "|    199304|2.6658014470000006E7|          2.805256204E7|                             -1394547.5699999928|\n",
      "|    199305| 2.886604335000001E7|           2.78214501E7|                              1044593.2500000075|\n",
      "|    199306| 2.567241958000001E7|   2.5229275750000007E7|                              443143.83000000194|\n",
      "|    199307|2.6389053530000016E7|   2.6655226179999992E7|                             -266172.64999997616|\n",
      "|    199308|2.7053172660000004E7|   2.9252365159999996E7|                             -2199192.4999999925|\n",
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT *\\\n",
    "                 ,LAG(Monthly_Revenue,12)OVER(ORDER BY Year_Month) AS Last_12_Monthly_Revenue\\\n",
    "                 ,Monthly_Revenue-LAG(Monthly_Revenue,12)OVER(ORDER BY Year_Month) AS Difference_Between_Previous_Year_Monthly_Revenue\\\n",
    "             FROM Revenue\\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
