{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 21:08:48,178 - root - INFO - ** Kedro project prospa\n",
      "2019-06-29 21:08:48,182 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/logging.yml\n",
      "2019-06-29 21:08:48,189 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/catalog.yml\n",
      "2019-06-29 21:08:48,196 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/credentials.yml\n",
      "2019-06-29 21:08:48,198 - anyconfig - INFO - Loading: /Users/Emil_Pastor/Documents/Projects/Startup/myanswer/interview-test-data-engineer/prospa/conf/base/parameters.yml\n",
      "2019-06-29 21:08:48,204 - root - INFO - Defined global variables proj_dir, proj_name, conf and io\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-29 21:08:48,212 - kedro.io.data_catalog - INFO - Loading data from `customer_dimension` (SparkDataSet)...\n",
      "2019-06-29 21:08:57,151 - kedro.io.data_catalog - INFO - Loading data from `part_dimension` (SparkDataSet)...\n",
      "2019-06-29 21:08:57,360 - kedro.io.data_catalog - INFO - Loading data from `supplier_dimension` (SparkDataSet)...\n",
      "2019-06-29 21:08:57,547 - kedro.io.data_catalog - INFO - Loading data from `order_fact` (SparkDataSet)...\n"
     ]
    }
   ],
   "source": [
    "customer_dimension = io.load(\"customer_dimension\")\n",
    "part_dimension = io.load(\"part_dimension\")\n",
    "supplier_dimension = io.load(\"supplier_dimension\")\n",
    "order_fact = io.load(\"order_fact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_dimension.registerTempTable(\"customer_dimension\")\n",
    "part_dimension.registerTempTable(\"part_dimension\")\n",
    "supplier_dimension.registerTempTable(\"supplier_dimension\")\n",
    "order_fact.registerTempTable(\"order_fact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the top 5 nations in terms of revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------+\n",
      "|Supplier_Country_Name|Supplier_Country_Revenue|\n",
      "+---------------------+------------------------+\n",
      "|        UNITED STATES|    1.7130294535100004E8|\n",
      "|                CHINA|     1.527625987020998E8|\n",
      "|           MOZAMBIQUE|        1.458187652671E8|\n",
      "|              VIETNAM|    1.2863593749619988E8|\n",
      "|                EGYPT|     1.270949754020999E8|\n",
      "+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"SELECT SD.Supplier_Country_Name\\\n",
    "                    ,SUM(OR.Order_Line_Revenue) AS Supplier_Country_Revenue\\\n",
    "                FROM order_fact OR \\\n",
    "          INNER JOIN supplier_dimension SD\\\n",
    "                  ON OR.Order_Supplier_Key=SD.Supplier_Key\\\n",
    "            GROUP BY SD.Supplier_Country_Name\\\n",
    "            ORDER BY Supplier_Country_Revenue DESC\").limit(5)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the top 5 nations, what is the most common shipping mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"Top_5_Nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+\n",
      "|Order_Ship_Mode|Shipping_Count|\n",
      "+---------------+--------------+\n",
      "|            FOB|           911|\n",
      "+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ship=spark.sql(\"SELECT OR.Order_Ship_Mode\\\n",
    "                    ,COUNT(DISTINCT OR.Order_Customer_Key) AS Shipping_Count \\\n",
    "                FROM order_fact OR \\\n",
    "          INNER JOIN supplier_dimension SD\\\n",
    "                  ON OR.Order_Supplier_Key=SD.Supplier_Key\\\n",
    "               WHERE SD.Supplier_Country_Name IN (SELECT Supplier_Country_Name FROM Top_5_Nations) \\\n",
    "            GROUP BY OR.Order_Ship_Mode\\\n",
    "            ORDER BY Shipping_Count DESC\").limit(1)\n",
    "df_ship.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the top selling months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|Year_Month|     Monthly_Revenue|\n",
      "+----------+--------------------+\n",
      "|    199312|     3.09095660532E7|\n",
      "|    199310|3.0758079172800012E7|\n",
      "|    199201|3.0537091363399997E7|\n",
      "|    199608|3.0231565316999994E7|\n",
      "|    199512|3.0143667112199996E7|\n",
      "|    199401| 2.997313480920004E7|\n",
      "|    199309|2.9957340914299995E7|\n",
      "|    199405| 2.974829256199999E7|\n",
      "|    199612| 2.957026777099999E7|\n",
      "|    199409|2.9489398987300012E7|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sell=spark.sql(\"SELECT YEAR(Order_Date)*100 + MONTH(Order_Date) AS Year_Month\\\n",
    "                         ,SUM(Order_Line_Revenue) AS Monthly_Revenue\\\n",
    "                     FROM order_fact\\\n",
    "                 GROUP BY Year_Month\\\n",
    "                 ORDER BY Monthly_Revenue DESC\")\n",
    "df_sell.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who are the top customer in terms of revenue and/or quantity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     Customer_Name| Customer_Revenue|\n",
      "+------------------+-----------------+\n",
      "|Customer#000001489|5418543.599999999|\n",
      "|Customer#000000214|     4684271.0263|\n",
      "|Customer#000001396|4655099.209099999|\n",
      "|Customer#000001246|     4651060.5863|\n",
      "|Customer#000000073|4648501.807700001|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CD.Customer_Name\\\n",
    "                 ,SUM(OR.Order_Line_Revenue) AS Customer_Revenue\\\n",
    "             FROM order_fact OR \\\n",
    "       INNER JOIN customer_dimension CD\\\n",
    "               ON OR.Order_Customer_Key=CD.Customer_Key\\\n",
    "         GROUP BY CD.Customer_Name\\\n",
    "         ORDER BY Customer_Revenue DESC\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     Customer_Name|Customer_Quantity|\n",
      "+------------------+-----------------+\n",
      "|Customer#000001489|             3868|\n",
      "|Customer#000001396|             3408|\n",
      "|Customer#000000073|             3384|\n",
      "|Customer#000000214|             3369|\n",
      "|Customer#000000898|             3309|\n",
      "+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CD.Customer_Name\\\n",
    "                 ,SUM(OR.Order_Line_Quantity) AS Customer_Quantity\\\n",
    "             FROM order_fact OR \\\n",
    "       INNER JOIN customer_dimension CD\\\n",
    "               ON OR.Order_Customer_Key=CD.Customer_Key\\\n",
    "         GROUP BY CD.Customer_Name\\\n",
    "         ORDER BY Customer_Quantity DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the sales revenue of on current period against previous period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revn=spark.sql(\"SELECT YEAR(Order_Date)*100 + MONTH(Order_Date) AS Year_Month\\\n",
    "                         ,SUM(Order_Line_Revenue) AS Monthly_Revenue\\\n",
    "                     FROM order_fact\\\n",
    "                 GROUP BY Year_Month\")\n",
    "df_revn.registerTempTable(\"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "|Year_Month|     Monthly_Revenue|Last_12_Monthly_Revenue|Difference_Between_Previous_Year_Monthly_Revenue|\n",
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "|    199201|3.0537091363399997E7|                   null|                                            null|\n",
      "|    199202| 2.473271612919999E7|                   null|                                            null|\n",
      "|    199203|2.9474009758200005E7|                   null|                                            null|\n",
      "|    199204|2.7840816030399997E7|                   null|                                            null|\n",
      "|    199205|2.7553435227700002E7|                   null|                                            null|\n",
      "|    199206|2.4983270502499998E7|                   null|                                            null|\n",
      "|    199207|2.6444198584999986E7|                   null|                                            null|\n",
      "|    199208|2.9103316365900002E7|                   null|                                            null|\n",
      "|    199209|2.7477849444999985E7|                   null|                                            null|\n",
      "|    199210| 2.665941230449999E7|                   null|                                            null|\n",
      "|    199211| 2.232585822489999E7|                   null|                                            null|\n",
      "|    199212| 2.453260528230001E7|                   null|                                            null|\n",
      "|    199301|2.5803046867000014E7|   3.0537091363399997E7|                              -4734044.496399984|\n",
      "|    199302|2.5931020141899996E7|    2.473271612919999E7|                              1198304.0127000064|\n",
      "|    199303|2.4563902040499993E7|   2.9474009758200005E7|                              -4910107.717700012|\n",
      "|    199304|     2.63810212941E7|   2.7840816030399997E7|                             -1459794.7362999953|\n",
      "|    199305| 2.857335601799999E7|   2.7553435227700002E7|                              1019920.7902999893|\n",
      "|    199306|     2.54146337992E7|   2.4983270502499998E7|                              431363.29670000076|\n",
      "|    199307| 2.618505496970001E7|   2.6444198584999986E7|                             -259143.61529997736|\n",
      "|    199308|2.6842306578100003E7|   2.9103316365900002E7|                              -2261009.787799999|\n",
      "+----------+--------------------+-----------------------+------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT *\\\n",
    "                 ,LAG(Monthly_Revenue,12)OVER(ORDER BY Year_Month) AS Last_12_Monthly_Revenue\\\n",
    "                 ,Monthly_Revenue-LAG(Monthly_Revenue,12)OVER(ORDER BY Year_Month) AS Difference_Between_Previous_Year_Monthly_Revenue\\\n",
    "             FROM Revenue\\\n",
    "          \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
